{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4c764726",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import re\n",
    "import html\n",
    "from bs4 import BeautifulSoup\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "BASE_URL = \"https://www.gob.mx\"\n",
    "ARCHIVE_URL = f\"{BASE_URL}/presidencia/es/archivo/articulos?filter_origin=archive&idiom=es&order=DESC&page=\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2e77e167",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_articles_from_page(page_num):\n",
    "    \"\"\"\n",
    "    Extract clean titles, URLs, and dates from Gob.mx dynamic HTML.\n",
    "    Args:\n",
    "        page_num (int): Page number to scrape.\n",
    "    Returns:\n",
    "        list of dict: Each dict contains 'title', 'url', and 'date' keys\n",
    "    \"\"\"\n",
    "    url = f\"{ARCHIVE_URL}{page_num}\"\n",
    "    r = requests.get(url)\n",
    "    r.raise_for_status()\n",
    "    text = r.text\n",
    "\n",
    "    # Extract JS-embedded HTML fragments\n",
    "    fragments = re.findall(r\"\\$\\('#prensa'\\)\\.append\\('(.+?)'\\);\", text, flags=re.DOTALL)\n",
    "\n",
    "    articles_out = []\n",
    "\n",
    "    for frag in fragments:\n",
    "        # Step 1: Decode HTML entities (e.g. &lt;, &quot;)\n",
    "        frag_clean = html.unescape(frag)\n",
    "        # Step 2: Replace escaped quotes \\\" â†’ \"\n",
    "        frag_clean = frag_clean.replace('\\\\\"', '\"').replace(\"\\\\'\", \"'\")\n",
    "        # Step 3: Remove stray backslashes that break tags\n",
    "        frag_clean = frag_clean.replace(\"\\\\n\", \"\").replace(\"\\\\\", \"\")\n",
    "        # Step 4: Parse\n",
    "        soup = BeautifulSoup(frag_clean, \"html.parser\")\n",
    "\n",
    "        # Extract all article cards\n",
    "        for art in soup.find_all(\"article\"):\n",
    "            title_el = art.find(\"h2\")\n",
    "            link_el = art.find(\"a\", class_=\"small-link\")\n",
    "            date_el = art.find(\"time\")\n",
    "\n",
    "            title = title_el.get_text(strip=True) if title_el else None\n",
    "            date = date_el.get_text(strip=True) if date_el else None\n",
    "\n",
    "            # Some hrefs may end with ?idiom=es\n",
    "            if link_el and link_el.has_attr(\"href\"):\n",
    "                href = link_el[\"href\"].strip('\"')\n",
    "                if href.startswith(\"/\"):\n",
    "                    href = BASE_URL + href\n",
    "            else:\n",
    "                href = None\n",
    "\n",
    "            if title or href:\n",
    "                articles_out.append({\n",
    "                    \"title\": title,\n",
    "                    \"url\": href,\n",
    "                    \"date\": date\n",
    "                })\n",
    "    return articles_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8947a447",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_all_articles(max_pages=50):\n",
    "    \"\"\"\n",
    "    Scrape articles from multiple pages.\n",
    "    Args:\n",
    "        max_pages (int): Maximum number of pages to scrape.\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame containing all scraped articles.\n",
    "    \"\"\"\n",
    "    all_data = []\n",
    "    # Loop through pages with progress bar\n",
    "    for page in tqdm(range(1, max_pages + 1)):\n",
    "        page_data = get_articles_from_page(page)   \n",
    "        if not page_data:\n",
    "            print(f\"No more data after page {page}.\") # Debug info\n",
    "            break\n",
    "        all_data.extend(page_data) # Accumulate data\n",
    "        time.sleep(1) # Be polite to the server\n",
    "    return pd.DataFrame(all_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
